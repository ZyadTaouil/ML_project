{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSCRK54nDGEU"
   },
   "source": [
    "---\n",
    "University Paris 1 Panthéon-Sorbonne \n",
    "\n",
    "Introduction to Machine Learning\n",
    "\n",
    "Dr. Nourhène BEN RABAH\n",
    "\n",
    "---\n",
    "\n",
    "# Lab 2: Data scaling, data normalization and data transformation \n",
    "\n",
    "#### You must send the notebook completed during the session on Discord.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercice1.\n",
    "\n",
    "You will apply label encoding for the vote column and On-hot encoding for the region column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pnd\n",
    "\n",
    "dfCategories = pnd.DataFrame (\n",
    "    [ ['male', 'from US', 'uses Safari', 'approves'], \n",
    "      ['female', 'from Europe', 'uses Firefox', 'disaproves'] ,\n",
    "      ['female', 'from US', 'uses Safari', 'approves'],\n",
    "      ['male', 'from Europe', 'uses Safari', 'approves'],\n",
    "      ['female', 'from US', 'uses Firefox', 'disaproves'] ,\n",
    "      ['male', 'from Europe', 'uses Chrome', 'disaproves'] , \n",
    "      ['female', 'from Asia', 'uses Chrome', 'approves'],\n",
    "      ['male', 'from Asia', 'uses Chrome', 'approves'] ],\n",
    "    columns=['sex', 'region','browser', 'vote' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Colors: [0 1 0 0 1 1 0 0]\n",
      "Encoded Data:\n",
      "   from Asia  from Europe  from US\n",
      "0      False        False     True\n",
      "1      False         True    False\n",
      "2      False        False     True\n",
      "3      False         True    False\n",
      "4      False        False     True\n",
      "5      False         True    False\n",
      "6       True        False    False\n",
      "7       True        False    False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform data\n",
    "encoded_colors = label_encoder.fit_transform(dfCategories['vote'])\n",
    "\n",
    "# Print encoded data\n",
    "print(\"Encoded Colors:\", encoded_colors)\n",
    "\n",
    "one_hot_encoded = pnd.get_dummies(dfCategories['region'])\n",
    "\n",
    "# Print One-Hot Encoded data\n",
    "print(\"Encoded Data:\")\n",
    "print(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercice2. IoT attack detection with Danmini.csv\n",
    "\n",
    "In this exercice, you will import the Danmini Dataset (Danmini. csv) which contains data to predict whether the IoT attack is bashlite or Mirai on a Danmini Doorbel device. \n",
    "\n",
    "- 1) Start by discovering the dataset (number of rows, columns, column types, target value to predict, see first rows and last rows, ... (as we did in the first lab) \n",
    "- 2) Data cleaning (see missing values and perform data cleaning)\n",
    "- 3) Data scaling, normalization \n",
    "- 4) data transformation (encode the numerical values). \n",
    "\n",
    "After these steps you can train your first ML algo, which we will discover in the next session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Import the dataset correctly \u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m Danmini \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDanmini.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m Danmini\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m      7\u001b[0m Danmini\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     (\n\u001b[1;32m   1745\u001b[0m         index,\n\u001b[1;32m   1746\u001b[0m         columns,\n\u001b[1;32m   1747\u001b[0m         col_dict,\n\u001b[0;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1749\u001b[0m         nrows\n\u001b[1;32m   1750\u001b[0m     )\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/python_parser.py:250\u001b[0m, in \u001b[0;36mPythonParser.read\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m, rows: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\n\u001b[1;32m    247\u001b[0m     Index \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, Sequence[Hashable] \u001b[38;5;241m|\u001b[39m MultiIndex, Mapping[Hashable, ArrayLike]\n\u001b[1;32m    248\u001b[0m ]:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 250\u001b[0m         content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(rows)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/python_parser.py:1135\u001b[0m, in \u001b[0;36mPythonParser._get_lines\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m   1132\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1135\u001b[0m     new_row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_iter_line(row_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m+\u001b[39m rows \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1136\u001b[0m     rows \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/python_parser.py:800\u001b[0m, in \u001b[0;36mPythonParser._next_iter_line\u001b[0;34m(self, row_num)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;66;03m# assert for mypy, data is Iterator[str] or None, would error in next\u001b[39;00m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 800\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(line, \u001b[38;5;28mlist\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#1\n",
    "import pandas as pd\n",
    "\n",
    "# Import the dataset correctly \n",
    "Danmini = pd.read_csv('Danmini.csv', sep = ',', engine = 'python')\n",
    "Danmini.info()\n",
    "Danmini.describe()\n",
    "df.dtypes\n",
    "first_rows = Danmini.loc[0:2]\n",
    "first_columns = Danmini.iloc[:, :3]\n",
    "print(\"3 first rows are :\\n\", first_rows)\n",
    "print(\"3 first columns are :\\n\", first_columns)\n",
    "Danmini.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "Danmini.dropna(axis='columns', how='all', inplace=True)\n",
    "Danmini.dropna(thresh=2, inplace=True)\n",
    "\n",
    "#Calculate calories column mean\n",
    "Danmini.fillna(Danmini.mean(), inplace=True)\n",
    "\n",
    "Danmini.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "scaled_data = scaler.fit_transform(Danmini, inplace=True)\n",
    "print(scaled_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Normalizer for L1 normalization\n",
    "normalizer_L1 = Normalizer(norm='l1') \n",
    "# Initialize Normalizer for L2 normalization\n",
    "normalizer_L2 = Normalizer(norm='l2')  \n",
    "\n",
    "# Apply L1 normalization\n",
    "normalized_data_L1 = normalizer_L1.transform(scaled_data, inplace=True)\n",
    "# Apply L2 normalization\n",
    "normalized_data_L2 = normalizer_L2.transform(scaled_data, inplace=True)\n",
    "\n",
    "print(\"\\nL1 Normalized Data:\")\n",
    "print(normalized_data_L1[:5])\n",
    "print(\"\\nL2 Normalized Data:\")\n",
    "print(normalized_data_L2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Perform One-Hot Encoding\n",
    "one_hot_encoded = pd.get_dummies(normalized_data_L1['Label'])\n",
    "\n",
    "print(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Project \n",
    "\n",
    "Let's move on to phase 1. Data preparation: \n",
    "You'll prepare the data by performing operations such as data cleaning, data normalization and transformation,\n",
    "To do this, you'll need to:\n",
    " - Describe your data, (number of rows, columns, column types, target value to predict, see first rows and last rows, ... (as we did in the first lab). \n",
    "- Describe the data cleaning technique(s) used (justify the decisions made)\n",
    "- Describe the data normalization, scaling and transformation methods used and justify the decisions made. \n",
    "- The code must be commented and explained. \n",
    "\n",
    "= You must send me your notebooks before the end of session 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows :  436\n",
      "Columns :  12\n",
      "Column types : ID        object\n",
      "M/F       object\n",
      "Hand      object\n",
      "Age        int64\n",
      "Educ     float64\n",
      "SES      float64\n",
      "MMSE     float64\n",
      "CDR      float64\n",
      "eTIV       int64\n",
      "nWBV     float64\n",
      "ASF      float64\n",
      "Delay    float64\n",
      "dtype: object\n",
      "Ten first rows : \n",
      "                ID M/F Hand  Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF  \\\n",
      "0  OAS1_0001_MR1   F    R   74   2.0  3.0  29.0  0.0  1344  0.743  1.306   \n",
      "1  OAS1_0002_MR1   F    R   55   4.0  1.0  29.0  0.0  1147  0.810  1.531   \n",
      "2  OAS1_0003_MR1   F    R   73   4.0  3.0  27.0  0.5  1454  0.708  1.207   \n",
      "3  OAS1_0004_MR1   M    R   28   NaN  NaN   NaN  NaN  1588  0.803  1.105   \n",
      "4  OAS1_0005_MR1   M    R   18   NaN  NaN   NaN  NaN  1737  0.848  1.010   \n",
      "5  OAS1_0006_MR1   F    R   24   NaN  NaN   NaN  NaN  1131  0.862  1.551   \n",
      "6  OAS1_0007_MR1   M    R   21   NaN  NaN   NaN  NaN  1516  0.830  1.157   \n",
      "7  OAS1_0009_MR1   F    R   20   NaN  NaN   NaN  NaN  1505  0.843  1.166   \n",
      "8  OAS1_0010_MR1   M    R   74   5.0  2.0  30.0  0.0  1636  0.689  1.073   \n",
      "9  OAS1_0011_MR1   F    R   52   3.0  2.0  30.0  0.0  1321  0.827  1.329   \n",
      "\n",
      "   Delay  \n",
      "0    NaN  \n",
      "1    NaN  \n",
      "2    NaN  \n",
      "3    NaN  \n",
      "4    NaN  \n",
      "5    NaN  \n",
      "6    NaN  \n",
      "7    NaN  \n",
      "8    NaN  \n",
      "9    NaN  \n",
      "Ten last rows : \n",
      "                 ID M/F Hand  Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF  \\\n",
      "426  OAS1_0202_MR2   F    R   23   NaN  NaN   NaN  NaN  1548  0.861  1.134   \n",
      "427  OAS1_0230_MR2   F    R   19   NaN  NaN   NaN  NaN  1577  0.849  1.113   \n",
      "428  OAS1_0236_MR2   F    R   20   NaN  NaN   NaN  NaN  1222  0.872  1.436   \n",
      "429  OAS1_0239_MR2   F    R   29   NaN  NaN   NaN  NaN  1438  0.822  1.221   \n",
      "430  OAS1_0249_MR2   F    R   28   NaN  NaN   NaN  NaN  1215  0.865  1.444   \n",
      "431  OAS1_0285_MR2   M    R   20   NaN  NaN   NaN  NaN  1469  0.847  1.195   \n",
      "432  OAS1_0353_MR2   M    R   22   NaN  NaN   NaN  NaN  1684  0.790  1.042   \n",
      "433  OAS1_0368_MR2   M    R   22   NaN  NaN   NaN  NaN  1580  0.856  1.111   \n",
      "434  OAS1_0379_MR2   F    R   20   NaN  NaN   NaN  NaN  1262  0.861  1.390   \n",
      "435  OAS1_0395_MR2   F    R   26   NaN  NaN   NaN  NaN  1283  0.834  1.368   \n",
      "\n",
      "     Delay  \n",
      "426   21.0  \n",
      "427   24.0  \n",
      "428    3.0  \n",
      "429   40.0  \n",
      "430    3.0  \n",
      "431    2.0  \n",
      "432   40.0  \n",
      "433   89.0  \n",
      "434    2.0  \n",
      "435   39.0  \n",
      "ID         0\n",
      "M/F        0\n",
      "Hand       0\n",
      "Age        0\n",
      "Educ     201\n",
      "SES      220\n",
      "MMSE     201\n",
      "CDR      201\n",
      "eTIV       0\n",
      "nWBV       0\n",
      "ASF        0\n",
      "Delay    416\n",
      "dtype: int64\n",
      "Number of rows :  373\n",
      "Columns :  15\n",
      "Column types : Subject ID     object\n",
      "MRI ID         object\n",
      "Group          object\n",
      "Visit           int64\n",
      "MR Delay        int64\n",
      "M/F            object\n",
      "Hand           object\n",
      "Age             int64\n",
      "EDUC            int64\n",
      "SES           float64\n",
      "MMSE          float64\n",
      "CDR           float64\n",
      "eTIV            int64\n",
      "nWBV          float64\n",
      "ASF           float64\n",
      "dtype: object\n",
      "Ten first rows : \n",
      "    Subject ID         MRI ID        Group  Visit  MR Delay M/F Hand  Age  EDUC  \\\n",
      "0  OAS2_0001  OAS2_0001_MR1  Nondemented      1         0   M    R   87    14   \n",
      "1  OAS2_0001  OAS2_0001_MR2  Nondemented      2       457   M    R   88    14   \n",
      "2  OAS2_0002  OAS2_0002_MR1     Demented      1         0   M    R   75    12   \n",
      "3  OAS2_0002  OAS2_0002_MR2     Demented      2       560   M    R   76    12   \n",
      "4  OAS2_0002  OAS2_0002_MR3     Demented      3      1895   M    R   80    12   \n",
      "5  OAS2_0004  OAS2_0004_MR1  Nondemented      1         0   F    R   88    18   \n",
      "6  OAS2_0004  OAS2_0004_MR2  Nondemented      2       538   F    R   90    18   \n",
      "7  OAS2_0005  OAS2_0005_MR1  Nondemented      1         0   M    R   80    12   \n",
      "8  OAS2_0005  OAS2_0005_MR2  Nondemented      2      1010   M    R   83    12   \n",
      "9  OAS2_0005  OAS2_0005_MR3  Nondemented      3      1603   M    R   85    12   \n",
      "\n",
      "   SES  MMSE  CDR  eTIV   nWBV    ASF  \n",
      "0  2.0  27.0  0.0  1987  0.696  0.883  \n",
      "1  2.0  30.0  0.0  2004  0.681  0.876  \n",
      "2  NaN  23.0  0.5  1678  0.736  1.046  \n",
      "3  NaN  28.0  0.5  1738  0.713  1.010  \n",
      "4  NaN  22.0  0.5  1698  0.701  1.034  \n",
      "5  3.0  28.0  0.0  1215  0.710  1.444  \n",
      "6  3.0  27.0  0.0  1200  0.718  1.462  \n",
      "7  4.0  28.0  0.0  1689  0.712  1.039  \n",
      "8  4.0  29.0  0.5  1701  0.711  1.032  \n",
      "9  4.0  30.0  0.0  1699  0.705  1.033  \n",
      "Ten last rows : \n",
      "     Subject ID         MRI ID        Group  Visit  MR Delay M/F Hand  Age  \\\n",
      "363  OAS2_0183  OAS2_0183_MR3  Nondemented      3       732   F    R   68   \n",
      "364  OAS2_0183  OAS2_0183_MR4  Nondemented      4      2107   F    R   72   \n",
      "365  OAS2_0184  OAS2_0184_MR1     Demented      1         0   F    R   72   \n",
      "366  OAS2_0184  OAS2_0184_MR2     Demented      2       553   F    R   73   \n",
      "367  OAS2_0185  OAS2_0185_MR1     Demented      1         0   M    R   80   \n",
      "368  OAS2_0185  OAS2_0185_MR2     Demented      2       842   M    R   82   \n",
      "369  OAS2_0185  OAS2_0185_MR3     Demented      3      2297   M    R   86   \n",
      "370  OAS2_0186  OAS2_0186_MR1  Nondemented      1         0   F    R   61   \n",
      "371  OAS2_0186  OAS2_0186_MR2  Nondemented      2       763   F    R   63   \n",
      "372  OAS2_0186  OAS2_0186_MR3  Nondemented      3      1608   F    R   65   \n",
      "\n",
      "     EDUC  SES  MMSE  CDR  eTIV   nWBV    ASF  \n",
      "363    13  2.0  30.0  0.0  1506  0.740  1.165  \n",
      "364    13  2.0  30.0  0.0  1510  0.723  1.162  \n",
      "365    16  3.0  24.0  0.5  1354  0.733  1.296  \n",
      "366    16  3.0  21.0  1.0  1351  0.708  1.299  \n",
      "367    16  1.0  28.0  0.5  1704  0.711  1.030  \n",
      "368    16  1.0  28.0  0.5  1693  0.694  1.037  \n",
      "369    16  1.0  26.0  0.5  1688  0.675  1.040  \n",
      "370    13  2.0  30.0  0.0  1319  0.801  1.331  \n",
      "371    13  2.0  30.0  0.0  1327  0.796  1.323  \n",
      "372    13  2.0  30.0  0.0  1333  0.801  1.317  \n",
      "Subject ID     0\n",
      "MRI ID         0\n",
      "Group          0\n",
      "Visit          0\n",
      "MR Delay       0\n",
      "M/F            0\n",
      "Hand           0\n",
      "Age            0\n",
      "EDUC           0\n",
      "SES           19\n",
      "MMSE           2\n",
      "CDR            0\n",
      "eTIV           0\n",
      "nWBV           0\n",
      "ASF            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# The Target value to predict is CDR \n",
    "# AD = Alzheimer Disease\n",
    "# CDR - Clinical Dementia Rating (0 = no dementia, 0.5 = very mild AD, 1 = mild AD, 2 = moderate AD, 3 = severe AD)\n",
    "\n",
    "# Datasets\n",
    "df=pd.read_csv('oasis_cross-sectional.csv', delimiter=',')\n",
    "df2=pd.read_csv('oasis_longitudinal.csv', delimiter=',')\n",
    "\n",
    "#1# #DESCRIPTION OF DATA\n",
    "# A # ### Data df (1st Dataset) ###\n",
    "#Number of rows\n",
    "number_of_rows = len(df)\n",
    "print(\"Number of rows : \",number_of_rows)\n",
    "#Columns\n",
    "columns = df.shape[1]\n",
    "print(\"Columns : \",columns)\n",
    "#Columns Type\n",
    "column_types = df.dtypes\n",
    "print(\"Column types :\", column_types)\n",
    "# ten First rows\n",
    "ten_first_rows = df.iloc[:10]\n",
    "print(\"Ten first rows : \\n \", ten_first_rows)\n",
    "# ten Last rows\n",
    "ten_last_rows = df.tail(10)\n",
    "print(\"Ten last rows : \\n\", ten_last_rows)\n",
    "#We look at the null values in df\n",
    "print(df.isna().sum())\n",
    "\n",
    "# A # ### Data df2 (2nd Dataset) ###\n",
    "#Number of rows\n",
    "number_of_rows = len(df2)\n",
    "print(\"Number of rows : \",number_of_rows)\n",
    "#Columns\n",
    "columns = df2.shape[1]\n",
    "print(\"Columns : \",columns)\n",
    "#Columns Type\n",
    "column_types = df2.dtypes\n",
    "print(\"Column types :\", column_types)\n",
    "# ten First rows\n",
    "ten_first_rows = df2.iloc[:10]\n",
    "print(\"Ten first rows : \\n \", ten_first_rows)\n",
    "# ten Last rows\n",
    "ten_last_rows = df2.tail(10)\n",
    "print(\"Ten last rows : \\n\", ten_last_rows)\n",
    "#We look at the null values in df_final\n",
    "print(df2.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Age        Educ        SES        MMSE         CDR         eTIV  \\\n",
      "count  809.000000  608.000000  570.00000  606.000000  608.000000   809.000000   \n",
      "mean    63.186650   10.184211    2.47193   27.234323    0.288651  1484.782447   \n",
      "std     23.117511    6.058388    1.12805    3.687980    0.377697   166.911689   \n",
      "min     18.000000    1.000000    1.00000    4.000000    0.000000  1106.000000   \n",
      "25%     49.000000    4.000000    2.00000   26.000000    0.000000  1361.000000   \n",
      "50%     72.000000   12.000000    2.00000   29.000000    0.000000  1475.000000   \n",
      "75%     80.000000   16.000000    3.00000   30.000000    0.500000  1583.000000   \n",
      "max     98.000000   23.000000    5.00000   30.000000    2.000000  2004.000000   \n",
      "\n",
      "             nWBV         ASF  \n",
      "count  809.000000  809.000000  \n",
      "mean     0.763037    1.197311  \n",
      "std      0.059401    0.133031  \n",
      "min      0.644000    0.876000  \n",
      "25%      0.715000    1.108000  \n",
      "50%      0.754000    1.190000  \n",
      "75%      0.817000    1.290000  \n",
      "max      0.893000    1.587000  \n",
      "df_final head:                ID M/F Hand  Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF\n",
      "0  OAS1_0001_MR1   F    R   74   2.0  3.0  29.0  0.0  1344  0.743  1.306\n",
      "1  OAS1_0002_MR1   F    R   55   4.0  1.0  29.0  0.0  1147  0.810  1.531\n",
      "2  OAS1_0003_MR1   F    R   73   4.0  3.0  27.0  0.5  1454  0.708  1.207\n",
      "3  OAS1_0004_MR1   M    R   28   NaN  NaN   NaN  NaN  1588  0.803  1.105\n",
      "4  OAS1_0005_MR1   M    R   18   NaN  NaN   NaN  NaN  1737  0.848  1.010\n",
      "df_final tail:              ID M/F Hand  Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF\n",
      "368  OAS2_0185   M    R   82  16.0  1.0  28.0  0.5  1693  0.694  1.037\n",
      "369  OAS2_0185   M    R   86  16.0  1.0  26.0  0.5  1688  0.675  1.040\n",
      "370  OAS2_0186   F    R   61  13.0  2.0  30.0  0.0  1319  0.801  1.331\n",
      "371  OAS2_0186   F    R   63  13.0  2.0  30.0  0.0  1327  0.796  1.323\n",
      "372  OAS2_0186   F    R   65  13.0  2.0  30.0  0.0  1333  0.801  1.317\n",
      "0\n",
      "M/F      0\n",
      "Age      0\n",
      "Educ     0\n",
      "SES     38\n",
      "MMSE     2\n",
      "CDR      0\n",
      "eTIV     0\n",
      "nWBV     0\n",
      "ASF      0\n",
      "dtype: int64\n",
      "One-Hot Encoded Gender Data:\n",
      "         F      M\n",
      "0     True  False\n",
      "1     True  False\n",
      "2     True  False\n",
      "8    False   True\n",
      "9     True  False\n",
      "..     ...    ...\n",
      "368  False   True\n",
      "369  False   True\n",
      "370   True  False\n",
      "371   True  False\n",
      "372   True  False\n",
      "\n",
      "[570 rows x 2 columns]\n",
      "df_final\n",
      "   Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF      F      M\n",
      "0   74   2.0  3.0  29.0  0.0  1344  0.743  1.306   True  False\n",
      "1   55   4.0  1.0  29.0  0.0  1147  0.810  1.531   True  False\n",
      "2   73   4.0  3.0  27.0  0.5  1454  0.708  1.207   True  False\n",
      "8   74   5.0  2.0  30.0  0.0  1636  0.689  1.073  False   True\n",
      "9   52   3.0  2.0  30.0  0.0  1321  0.827  1.329   True  False\n",
      "df_final\n",
      "   Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF      F      M\n",
      "0   74   2.0  3.0  29.0    0  1344  0.743  1.306   True  False\n",
      "1   55   4.0  1.0  29.0    0  1147  0.810  1.531   True  False\n",
      "2   73   4.0  3.0  27.0    1  1454  0.708  1.207   True  False\n",
      "8   74   5.0  2.0  30.0    0  1636  0.689  1.073  False   True\n",
      "9   52   3.0  2.0  30.0    0  1321  0.827  1.329   True  False\n",
      "df_final\n",
      "   Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF      F      M\n",
      "0   74   2.0    2  29.0    0  1344  0.743  1.306   True  False\n",
      "1   55   4.0    0  29.0    0  1147  0.810  1.531   True  False\n",
      "2   73   4.0    2  27.0    1  1454  0.708  1.207   True  False\n",
      "8   74   5.0    1  30.0    0  1636  0.689  1.073  False   True\n",
      "9   52   3.0    1  30.0    0  1321  0.827  1.329   True  False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "#Datasets\n",
    "df=pd.read_csv('oasis_cross-sectional.csv', delimiter=',')\n",
    "df2=pd.read_csv('oasis_longitudinal.csv', delimiter=',')\n",
    "\n",
    "#The first and second datasets have the same data with the second having more attributes\n",
    "#We prepare the dataset df2 for merging with df dataset, by dropping and renaming columns\n",
    "#2) 4) Data Cleaning and Encoding\n",
    "df2=df2.rename(columns={\"EDUC\" : \"Educ\"})\n",
    "df2=df2.rename(columns={\"Subject ID\" : \"ID\"})\n",
    "df=df.drop(columns=['Delay'])\n",
    "\n",
    "#MR delay is an unknown parameter, Group is duplicated with CDR it says if a person has alzheimer or not but CDR already\n",
    "#indicates if one has Alzheimer, Visit is the number of visits and MRI id is the MRI id \n",
    "df2=df2.drop(columns=['Group','Visit', 'MR Delay', 'MRI ID'])\n",
    "df_final= pd.concat([df, df2], axis=0)\n",
    "#Looking at the combined dataset\n",
    "print(df_final.describe())\n",
    "print(\"df_final head: \",df_final.head(5))\n",
    "print(\"df_final tail: \",df_final.tail(5))\n",
    "\n",
    "#We are dropping the null CDR as CDR is the target value and cannot have null values\n",
    "df_final = df_final.dropna(subset = ['CDR'])\n",
    "#The ID has no correlation with CDR so we drop the column\n",
    "df_final=df_final.drop(columns='ID')\n",
    "#In the dataset There are only right handed people so we drop the column\n",
    "subject_left_handed = len(df_final[df_final['Hand'] != 'R'])\n",
    "print(subject_left_handed)\n",
    "df_final=df_final.drop(columns='Hand')\n",
    "\n",
    "#We are looking at the remaining null values after dropping null CDR\n",
    "print(df_final.isna().sum())\n",
    "#SES is composed of discrete int values which represents the socioeconomical status of the person (from 1=highest status\n",
    "#to 5=lower status), it is not pertinent to do a mean or median on this column and there are only 38 values missing\n",
    "#which is negligeable\n",
    "df_final=df_final.dropna(subset=['SES'])\n",
    "\n",
    "#After this drop there is no more null values, We can start encoding the values\n",
    "\n",
    "# Perform One-Hot Encoding on M/F (Gender) column, append the one hot encoded columns and delete the M/F column\n",
    "one_hot_encoded_gender = pd.get_dummies(df_final['M/F'])\n",
    "print(\"One-Hot Encoded Gender Data:\")\n",
    "print(one_hot_encoded_gender)\n",
    "df_final= pd.concat([df_final, one_hot_encoded_gender], axis=1)\n",
    "df_final= df_final.drop(columns=['M/F'])\n",
    "print(\"df_final\")\n",
    "print(df_final.head(5))\n",
    "\n",
    "\n",
    "#Perform Label Encoding on CDR (Clinical Dementia Rating) column, we perform label encoding because the numbers \n",
    "#represent the degree of dementia of a person\n",
    "label_encoder = LabelEncoder()\n",
    "df_final['encoded_class_cdr'] = label_encoder.fit_transform(df_final['CDR'])\n",
    "df_final['CDR']=df_final['encoded_class_cdr']\n",
    "df_final=df_final.drop(columns=['encoded_class_cdr'])\n",
    "print(\"df_final\")\n",
    "print(df_final.head(5))\n",
    "\n",
    "#Perform Label Encoding on SES (from 1=highest status to 5=lower status), it is a hierarchical value so it is pertinent\n",
    "#to perform label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df_final['encoded_class_ses'] = label_encoder.fit_transform(df_final['SES'])\n",
    "df_final['SES']=df_final['encoded_class_ses']\n",
    "df_final=df_final.drop(columns=['encoded_class_ses'])\n",
    "print(\"df_final\")\n",
    "print(df_final.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "8    0\n",
      "9    0\n",
      "Name: CDR, dtype: int64\n",
      "          Age      Educ   SES      MMSE      eTIV      nWBV       ASF    F  \\\n",
      "0    0.630769  0.045455  0.50  0.961538  0.265033  0.502538  0.604782  1.0   \n",
      "1    0.338462  0.136364  0.00  0.961538  0.045657  0.842640  0.921238  1.0   \n",
      "2    0.615385  0.136364  0.50  0.884615  0.387528  0.324873  0.465541  1.0   \n",
      "3    0.630769  0.181818  0.25  1.000000  0.590200  0.228426  0.277075  0.0   \n",
      "4    0.292308  0.090909  0.25  1.000000  0.239421  0.928934  0.637131  1.0   \n",
      "..        ...       ...   ...       ...       ...       ...       ...  ...   \n",
      "565  0.753846  0.681818  0.00  0.923077  0.653675  0.253807  0.226442  0.0   \n",
      "566  0.815385  0.681818  0.00  0.846154  0.648107  0.157360  0.230661  0.0   \n",
      "567  0.430769  0.545455  0.25  1.000000  0.237194  0.796954  0.639944  1.0   \n",
      "568  0.461538  0.545455  0.25  1.000000  0.246102  0.771574  0.628692  1.0   \n",
      "569  0.492308  0.545455  0.25  1.000000  0.252784  0.796954  0.620253  1.0   \n",
      "\n",
      "       M  CDR  \n",
      "0    0.0    0  \n",
      "1    0.0    0  \n",
      "2    0.0    1  \n",
      "3    1.0    0  \n",
      "4    0.0    0  \n",
      "..   ...  ...  \n",
      "565  1.0    1  \n",
      "566  1.0    1  \n",
      "567  0.0    0  \n",
      "568  0.0    0  \n",
      "569  0.0    0  \n",
      "\n",
      "[570 rows x 10 columns]\n",
      "Original Data:\n",
      "      Age  Educ  SES  MMSE  eTIV   nWBV    ASF      F      M\n",
      "0     74   2.0    2  29.0  1344  0.743  1.306   True  False\n",
      "1     55   4.0    0  29.0  1147  0.810  1.531   True  False\n",
      "2     73   4.0    2  27.0  1454  0.708  1.207   True  False\n",
      "8     74   5.0    1  30.0  1636  0.689  1.073  False   True\n",
      "9     52   3.0    1  30.0  1321  0.827  1.329   True  False\n",
      "..   ...   ...  ...   ...   ...    ...    ...    ...    ...\n",
      "368   82  16.0    0  28.0  1693  0.694  1.037  False   True\n",
      "369   86  16.0    0  26.0  1688  0.675  1.040  False   True\n",
      "370   61  13.0    1  30.0  1319  0.801  1.331   True  False\n",
      "371   63  13.0    1  30.0  1327  0.796  1.323   True  False\n",
      "372   65  13.0    1  30.0  1333  0.801  1.317   True  False\n",
      "\n",
      "[570 rows x 9 columns]\n",
      "Normalized Data:\n",
      "           Age      Educ   SES      MMSE      eTIV      nWBV       ASF    F  \\\n",
      "0    0.630769  0.045455  0.50  0.961538  0.265033  0.502538  0.604782  1.0   \n",
      "1    0.338462  0.136364  0.00  0.961538  0.045657  0.842640  0.921238  1.0   \n",
      "2    0.615385  0.136364  0.50  0.884615  0.387528  0.324873  0.465541  1.0   \n",
      "3    0.630769  0.181818  0.25  1.000000  0.590200  0.228426  0.277075  0.0   \n",
      "4    0.292308  0.090909  0.25  1.000000  0.239421  0.928934  0.637131  1.0   \n",
      "..        ...       ...   ...       ...       ...       ...       ...  ...   \n",
      "565  0.753846  0.681818  0.00  0.923077  0.653675  0.253807  0.226442  0.0   \n",
      "566  0.815385  0.681818  0.00  0.846154  0.648107  0.157360  0.230661  0.0   \n",
      "567  0.430769  0.545455  0.25  1.000000  0.237194  0.796954  0.639944  1.0   \n",
      "568  0.461538  0.545455  0.25  1.000000  0.246102  0.771574  0.628692  1.0   \n",
      "569  0.492308  0.545455  0.25  1.000000  0.252784  0.796954  0.620253  1.0   \n",
      "\n",
      "       M  CDR  \n",
      "0    0.0    0  \n",
      "1    0.0    0  \n",
      "2    0.0    1  \n",
      "3    1.0    0  \n",
      "4    0.0    0  \n",
      "..   ...  ...  \n",
      "565  1.0    1  \n",
      "566  1.0    1  \n",
      "567  0.0    0  \n",
      "568  0.0    0  \n",
      "569  0.0    0  \n",
      "\n",
      "[570 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#3) Data normalization\n",
    "#There ranges between the values such as eTIV, nWBV or Educ is wide so we found pertinent to use\n",
    "#as seen in the df_final.describe() before\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "column_to_exclude = 'CDR'\n",
    "\n",
    "# Separate the column to exclude from scaling\n",
    "column_to_exclude_data = df_final[column_to_exclude]\n",
    "print(column_to_exclude_data.head())\n",
    "\n",
    "# Drop the column to exclude from the DataFrame\n",
    "df_final = df_final.drop(columns=[column_to_exclude])\n",
    "\n",
    "df_final_normalized = scaler.fit_transform(df_final)\n",
    "\n",
    "# Convert the scaled data back to DataFrame\n",
    "scaled_df = pd.DataFrame(df_final_normalized, columns=df_final.columns)\n",
    "\n",
    "# Ensure the index of both DataFrames aligns correctly\n",
    "scaled_df = scaled_df.reset_index(drop=True)\n",
    "column_to_exclude_data = column_to_exclude_data.reset_index(drop=True)\n",
    "\n",
    "# Add the excluded column back to the DataFrame\n",
    "scaled_df[column_to_exclude] = column_to_exclude_data\n",
    "\n",
    "# Output scaled DataFrame\n",
    "print(scaled_df)\n",
    "\n",
    "print(\"Original Data:\\n\", df_final)\n",
    "print(\"Normalized Data:\\n\", scaled_df)\n",
    "scaled_df.to_csv('oasis_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nColumns Description :\\n\\nDemographics Info :\\nM.F - Gender\\nHand - Handedness (actually all subjects were right-handed so I will drop this column)\\nAge - in years\\nEDUC - Years of education \\nRange: 1 to 23.\\nSES - Socioeconomic status as assessed by the Hollingshead Index of Social Position and classified into categories from 1 (highest status) to 5 (lowest status)\\n\\nClinical Info : \\nMMSE - Mini-Mental State Examination score commonly used in medicine to measure cognitive impairmen (range is from 0 = worst to 30 = best)\\nCDR - Clinical Dementia Rating (0 = no dementia, 0.5 = very mild AD, 1 = mild AD, 2 = moderate AD, 3 = severe AD)\\n\\nDerived anatomic volumes\\neTIV (Estimated Total Intracranial Volume) - Estimated total intracranial volume, mm3.\\nRange: 1106 to 2084.\\nnWBV (Normalized Whole Brain Volume) - Normalized whole-brain volume, expressed as a percent of all voxels in the atlas-masked image that are labeled as gray or white matter by the automated tissue segmentation process.\\nRange: 0.644 to 0.893 (it is a ratio, so no unit).\\nASF (Atlas Scaling Factor) - Computed scaling factor that transforms native-space brain and skull to the atlas target (i.e., the determinant of the transform matrix)\\nRange: 0.876 to 1.587 (unitless ratio).\\n\\nDropped columns :\\ngroup : Column is a duplicate of CDR from the first dataset, as it indicates the stages of AD in text. So we decided to drop it.\\nVisit : Irrelevant data + not included in first dataset.\\nMR Delay : No information on usage and many null data\\nMRI ID : Not necessary to have an ID\\nSubject ID : Not necessary to have an ID\\nHand : All subjects are right-handed\\n\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Columns Description :\n",
    "\n",
    "Demographics Info :\n",
    "M.F - Gender\n",
    "Hand - Handedness (actually all subjects were right-handed so I will drop this column)\n",
    "Age - in years\n",
    "EDUC - Years of education \n",
    "Range: 1 to 23.\n",
    "SES - Socioeconomic status as assessed by the Hollingshead Index of Social Position and classified into categories from 1 (highest status) to 5 (lowest status)\n",
    "\n",
    "Clinical Info : \n",
    "MMSE - Mini-Mental State Examination score commonly used in medicine to measure cognitive impairmen (range is from 0 = worst to 30 = best)\n",
    "CDR - Clinical Dementia Rating (0 = no dementia, 0.5 = very mild AD, 1 = mild AD, 2 = moderate AD, 3 = severe AD)\n",
    "\n",
    "Derived anatomic volumes\n",
    "eTIV (Estimated Total Intracranial Volume) - Estimated total intracranial volume, mm3.\n",
    "Range: 1106 to 2084.\n",
    "nWBV (Normalized Whole Brain Volume) - Normalized whole-brain volume, expressed as a percent of all voxels in the atlas-masked image that are labeled as gray or white matter by the automated tissue segmentation process.\n",
    "Range: 0.644 to 0.893 (it is a ratio, so no unit).\n",
    "ASF (Atlas Scaling Factor) - Computed scaling factor that transforms native-space brain and skull to the atlas target (i.e., the determinant of the transform matrix)\n",
    "Range: 0.876 to 1.587 (unitless ratio).\n",
    "\n",
    "Dropped columns :\n",
    "group : Column is a duplicate of CDR from the first dataset, as it indicates the stages of AD in text. So we decided to drop it.\n",
    "Visit : Irrelevant data + not included in first dataset.\n",
    "MR Delay : No information on usage and many null data\n",
    "MRI ID : Not necessary to have an ID\n",
    "Subject ID : Not necessary to have an ID\n",
    "Hand : All subjects are right-handed\n",
    "\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab_1_ESIEECom_Campagnes_de_publicité.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
